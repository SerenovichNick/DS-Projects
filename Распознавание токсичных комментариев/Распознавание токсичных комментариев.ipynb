{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовим библиотеки, которые понадобятся нам в проекте.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Отключение всех предупреждений\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Первым делом загрузим данные и подготовим их для обучения модели. Это включает в себя обработку текста и разбиение данных на обучающую и тестовую выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "\n",
    "# Проверка данных\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лемматизируем текст с помощью WordNetLemmatizer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для преобразования Penn Treebank тегов в WordNet теги\n",
    "def penn2morphy(penntag):\n",
    "    morphy_tag = {'NN': 'n', 'JJ': 'a', 'VB': 'v', 'RB': 'r'}\n",
    "    return morphy_tag.get(penntag[:2], 'n')\n",
    "\n",
    "# Функция для лемматизации текста\n",
    "def lemmatize_sent(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    return ' '.join([wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) for word, tag in pos_tag(word_tokenize(text))])\n",
    "\n",
    "# Применение лемматизации к тексту\n",
    "data['text'] = data['text'].apply(lemmatize_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выделим из датасета признаки и целевую переменную. Остальные столбцы нам не потребуются.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на признаки и целевую переменную\n",
    "X = data['text']\n",
    "y = data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разобьем данные на обучающую и тестовую выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преобразуем текст в числовой формат с помощью TF-IDF.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование текста в числовой формат с помощью TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные подготовлены. Приступим к обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создадим пайплайн и обучим 3 модели: логистическую, градиентный бустинг и случайный лес.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель: Pipeline(steps=[('tfidf', TfidfVectorizer(max_features=5000)),\n",
      "                ('clf', LogisticRegression(C=20))])\n",
      "Лучший F1 показатель: 0.7850787132101301\n",
      "Лучшие гиперпараметры: {'clf': LogisticRegression(C=20), 'clf__C': 20}\n"
     ]
    }
   ],
   "source": [
    "# Создание пайплайна для логистической регрессии, градиентного бустинга и случайного леса\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('clf', LogisticRegression())  # Место держатель для классификатора\n",
    "])\n",
    "\n",
    "# Параметры для подбора гиперпараметров\n",
    "param_grid = [\n",
    "    {\n",
    "        'clf': [LogisticRegression()],\n",
    "        'clf__C': [1, 10, 20]\n",
    "    },\n",
    "    {\n",
    "        'clf': [GradientBoostingClassifier(random_state=42)],\n",
    "    },\n",
    "    {\n",
    "        'clf': [RandomForestClassifier(random_state=42)],\n",
    "        'clf__n_estimators': [5, 10],\n",
    "        'clf__max_depth': [5, 10, 20, 50, 100]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Поиск по сетке с кросс-валидацией для всех моделей\n",
    "grid = GridSearchCV(pipeline, param_grid, scoring='f1', cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Лучшая модель\n",
    "best_model = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# Тестирование лучшей модели на тестовой выборке\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "f1_best = f1_score(y_test, y_pred_best)\n",
    "\n",
    "print(f'Лучшая модель: {best_model}')\n",
    "print(f'Лучший F1 показатель: {f1_best}')\n",
    "print(f'Лучшие гиперпараметры: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучше всего себя из коробки показала Логистическая регрессия. Подкорректируем ее гиперпараметры чтобы добиться показателя f1 выше 0.75.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 показатель для логистической регрессии с гиперпараметрами: 0.7838953888506539\n",
      "Лучший гиперпараметр Логистической регрессии: {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "# Подбор гиперпараметров для логистической регрессии\n",
    "param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "grid_logreg = GridSearchCV(LogisticRegression(), param_grid, scoring='f1')\n",
    "grid_logreg.fit(X_train_tfidf, y_train)\n",
    "best_logreg = grid_logreg.best_estimator_\n",
    "y_pred_best_logreg = best_logreg.predict(X_test_tfidf)\n",
    "f1_best_logreg = f1_score(y_test, y_pred_best_logreg)\n",
    "print(f'Best F1 показатель для логистической регрессии с гиперпараметрами: {f1_best_logreg}')\n",
    "print(f'Лучший гиперпараметр Логистической регрессии: {grid_logreg.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшей моделью оказалась логистическая регрессия с регуляризацией C=10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы провели обучение трех моделей классификации комментариев на токсичные и нетоксичные: логистической регрессии, градиентного бустинга и случайного леса. Давайте подробно рассмотрим результаты каждой модели и подведем итоги.\n",
    "\n",
    "**Логистическая регрессия**\n",
    "\n",
    "Первоначально логистическая регрессия показала F1-метрику 0.736. Это значение демонстрирует, что модель достаточно хорошо справляется с задачей классификации, но все же есть потенциал для улучшения. Для повышения качества модели мы применили метод подбора гиперпараметров (GridSearchCV), чтобы найти наилучший параметр регуляризации `C`.\n",
    "\n",
    "После подбора гиперпараметров (при лучшем значении `C=10`) F1-метрика для логистической регрессии улучшилась до 0.772. Это свидетельствует о значительном повышении точности модели, и данное значение превышает необходимый порог в 0.75.\n",
    "\n",
    "**Градиентный бустинг**\n",
    "\n",
    "Модель градиентного бустинга показала F1-метрику 0.596. Это самый низкий результат среди всех трех моделей. Возможно, модель требует более тщательной настройки гиперпараметров или увеличения объема данных для обучения. В текущем виде модель градиентного бустинга не достигает необходимого уровня качества.\n",
    "\n",
    "**Случайный лес**\n",
    "\n",
    "Модель случайного леса показала F1-метрику 0.708. Этот результат лучше, чем у градиентного бустинга, но все же ниже, чем у логистической регрессии до и после подбора гиперпараметров. Тем не менее, модель случайного леса показала себя достаточно хорошо и может быть улучшена дополнительной настройкой параметров.\n",
    "\n",
    "**Показатели**\n",
    "\n",
    "1. **Логистическая регрессия**:\n",
    "   - F1 score: 0.736\n",
    "   - F1 score после подбора гиперпараметров: 0.783\n",
    "   - Лучший гиперпараметр `C=10`\n",
    "\n",
    "2. **Градиентный бустинг**:\n",
    "   - F1 score: 0.596\n",
    "\n",
    "3. **Случайный лес**:\n",
    "   - F1 score: 0.708\n",
    "\n",
    "Из всех моделей логистическая регрессия, особенно после подбора гиперпараметров, показала наилучший результат. Она превысила необходимый порог F1-метрики в 0.75, что делает ее лучшим выбором для задачи классификации токсичных комментариев в данном проекте.\n",
    "\n",
    "Модель градиентного бустинга требует значительного улучшения, чтобы стать конкурентоспособной, а модель случайного леса показала средние результаты и также может быть улучшена дополнительной настройкой гиперпараметров."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1181,
    "start_time": "2024-06-22T06:57:04.006Z"
   },
   {
    "duration": 10291,
    "start_time": "2024-06-22T06:57:36.699Z"
   },
   {
    "duration": 36,
    "start_time": "2024-06-22T06:59:22.271Z"
   },
   {
    "duration": 2024,
    "start_time": "2024-06-22T07:01:38.595Z"
   },
   {
    "duration": 2042,
    "start_time": "2024-06-22T07:01:51.250Z"
   },
   {
    "duration": 2,
    "start_time": "2024-06-22T07:02:35.269Z"
   },
   {
    "duration": 2006,
    "start_time": "2024-06-22T07:02:38.760Z"
   },
   {
    "duration": 178978,
    "start_time": "2024-06-22T07:03:45.077Z"
   },
   {
    "duration": 314942,
    "start_time": "2024-06-22T07:07:49.573Z"
   },
   {
    "duration": 30320,
    "start_time": "2024-06-22T07:15:02.211Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-22T07:17:09.313Z"
   },
   {
    "duration": 7,
    "start_time": "2024-06-22T07:17:31.942Z"
   },
   {
    "duration": 1071,
    "start_time": "2024-06-22T07:25:44.213Z"
   },
   {
    "duration": 7760,
    "start_time": "2024-06-22T07:25:45.286Z"
   },
   {
    "duration": 2063,
    "start_time": "2024-06-22T07:25:53.048Z"
   },
   {
    "duration": 185463,
    "start_time": "2024-06-22T07:25:55.113Z"
   },
   {
    "duration": 322990,
    "start_time": "2024-06-22T07:29:00.578Z"
   },
   {
    "duration": 31262,
    "start_time": "2024-06-22T07:34:23.569Z"
   },
   {
    "duration": 9596,
    "start_time": "2024-06-22T07:35:20.760Z"
   },
   {
    "duration": 2569,
    "start_time": "2024-06-22T10:43:56.636Z"
   },
   {
    "duration": 12495,
    "start_time": "2024-06-22T10:43:59.207Z"
   },
   {
    "duration": 2469,
    "start_time": "2024-06-22T10:44:11.705Z"
   },
   {
    "duration": 211525,
    "start_time": "2024-06-22T10:44:14.176Z"
   },
   {
    "duration": 373137,
    "start_time": "2024-06-22T10:47:45.703Z"
   },
   {
    "duration": 36838,
    "start_time": "2024-06-22T10:53:58.842Z"
   },
   {
    "duration": 39,
    "start_time": "2024-06-23T04:38:16.711Z"
   },
   {
    "duration": 6,
    "start_time": "2024-06-23T04:40:44.450Z"
   },
   {
    "duration": 5,
    "start_time": "2024-06-23T04:48:26.519Z"
   },
   {
    "duration": 1136,
    "start_time": "2024-06-23T04:49:49.516Z"
   },
   {
    "duration": 3105,
    "start_time": "2024-06-23T04:49:50.653Z"
   },
   {
    "duration": 339,
    "start_time": "2024-06-23T04:49:53.759Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:49:54.099Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:49:54.100Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:49:54.101Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:49:54.102Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:49:54.103Z"
   },
   {
    "duration": 1113,
    "start_time": "2024-06-23T04:50:32.200Z"
   },
   {
    "duration": 757,
    "start_time": "2024-06-23T04:50:33.315Z"
   },
   {
    "duration": 312,
    "start_time": "2024-06-23T04:50:34.074Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:50:34.387Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:50:34.388Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:50:34.389Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:50:34.390Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:50:34.391Z"
   },
   {
    "duration": 1034,
    "start_time": "2024-06-23T04:52:05.719Z"
   },
   {
    "duration": 771,
    "start_time": "2024-06-23T04:52:06.754Z"
   },
   {
    "duration": 323,
    "start_time": "2024-06-23T04:52:07.526Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:52:07.851Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:52:07.852Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:52:07.853Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:52:07.853Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:52:07.854Z"
   },
   {
    "duration": 1149,
    "start_time": "2024-06-23T04:53:02.699Z"
   },
   {
    "duration": 753,
    "start_time": "2024-06-23T04:53:03.850Z"
   },
   {
    "duration": 119110,
    "start_time": "2024-06-23T04:53:04.605Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:55:03.716Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:55:03.717Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:55:03.718Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:55:03.719Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:55:03.719Z"
   },
   {
    "duration": 1100,
    "start_time": "2024-06-23T04:56:56.620Z"
   },
   {
    "duration": 768,
    "start_time": "2024-06-23T04:56:57.722Z"
   },
   {
    "duration": 3,
    "start_time": "2024-06-23T04:56:58.491Z"
   },
   {
    "duration": 96,
    "start_time": "2024-06-23T04:56:58.496Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:56:58.593Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:56:58.594Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:56:58.595Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:56:58.596Z"
   },
   {
    "duration": 1106,
    "start_time": "2024-06-23T04:57:37.623Z"
   },
   {
    "duration": 772,
    "start_time": "2024-06-23T04:57:38.731Z"
   },
   {
    "duration": 4,
    "start_time": "2024-06-23T04:57:39.504Z"
   },
   {
    "duration": 13,
    "start_time": "2024-06-23T04:57:39.509Z"
   },
   {
    "duration": 26,
    "start_time": "2024-06-23T04:57:39.524Z"
   },
   {
    "duration": 6562,
    "start_time": "2024-06-23T04:57:39.551Z"
   },
   {
    "duration": 64917,
    "start_time": "2024-06-23T04:57:46.114Z"
   },
   {
    "duration": 0,
    "start_time": "2024-06-23T04:58:51.032Z"
   },
   {
    "duration": 1095,
    "start_time": "2024-06-23T04:58:59.660Z"
   },
   {
    "duration": 788,
    "start_time": "2024-06-23T04:59:00.756Z"
   },
   {
    "duration": 420887,
    "start_time": "2024-06-23T04:59:01.545Z"
   },
   {
    "duration": 3,
    "start_time": "2024-06-23T05:06:02.433Z"
   },
   {
    "duration": 45,
    "start_time": "2024-06-23T05:06:02.437Z"
   },
   {
    "duration": 5802,
    "start_time": "2024-06-23T05:06:02.483Z"
   },
   {
    "duration": 1288442,
    "start_time": "2024-06-23T05:06:08.287Z"
   },
   {
    "duration": 30998,
    "start_time": "2024-06-23T05:27:36.730Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
